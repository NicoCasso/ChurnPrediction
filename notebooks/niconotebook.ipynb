{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1b5428",
   "metadata": {},
   "source": [
    "# Brief Métier : Prédiction de Churn Clients avec le Deep Learning\n",
    "\n",
    "## 1. Contexte professionnel\n",
    "Vous êtes Data Scientists dans une ESN (Entreprise de Services Numériques) qui accompagne les opérateurs télécoms dans la réduction de la perte d’abonnés.\n",
    "Votre nouveau client, TelcoNova, souhaite anticiper les départs de ses clients (churn) afin d’orienter ses campagnes de rétention.\n",
    "Il met à votre disposition un extrait anonymisé de sa base CRM (le jeu Telco Customer Churn, déjà pré-nettoyé en grande partie) et vous laisse 3 jours pour livrer un premier prototype de modèle de prédiction exploitable en production.\n",
    "TelcoNova exige un livrable reproductible et facilement intégrable par ses équipes MLOps ; vous travaillerez en binôme, en suivant les bonnes pratiques Git / GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5806396",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Votre mission\n",
    "\n",
    "### 1. Explorer & préparer les données :\n",
    "\n",
    "audit qualité, gestion des valeurs manquantes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataframe = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "for index, column in enumerate ( dataframe.columns) :\n",
    "    print(f\"{index}: {column}, \", end='')\n",
    "    num_values = dataframe[column].nunique()\n",
    "    is_numeric = pd.api.types.is_numeric_dtype(dataframe[column])\n",
    "    numeric_type = str(dataframe[column].dtype)\n",
    "    print(f\"{num_values}{(' '+numeric_type) if is_numeric else ''} values\", end='')\n",
    "    if num_values < 10 :\n",
    "        print(f\": \" + ', '.join(str(x) for x in dataframe[column].unique())) \n",
    "    else :\n",
    "        print(f\".\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28543bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration des colonnes à plus de 10 valeurs\n",
    "\n",
    "def check_float(dataframe : pd.DataFrame, columnname : str) :\n",
    "    print(f\"{columnname}:\")\n",
    "    numericount =0\n",
    "    for value in dataframe[columnname].unique() :\n",
    "        try :\n",
    "            numeric_value = float(value)\n",
    "            numericount+=1\n",
    "        except :\n",
    "            print(f\"  [{value}]\")\n",
    "\n",
    "    print(f\"{numericount} values\")\n",
    "    print()\n",
    "\n",
    "# 0: customerID, 7043 values => drop column\n",
    "# 5: tenure, 73 int64 values => int64\n",
    "# 18: MonthlyCharges, 1585 float64 values => float64\n",
    "check_float(dataframe, 'MonthlyCharges')\n",
    "\n",
    "# 19: TotalCharges, 6531 values : Exploration\n",
    "check_float(dataframe, 'TotalCharges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le chemin absolu du dossier src au sys.path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from pipeline_functions import exclude_spaces\n",
    "\n",
    "print(f\"before : {dataframe['TotalCharges'].dtype}\")\n",
    "\n",
    "dataframe2 = exclude_spaces('TotalCharges')(dataframe)\n",
    "\n",
    "print(f\"after : {dataframe2['TotalCharges'].dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892c9ee",
   "metadata": {},
   "source": [
    "encodage des variables / normalisation / standardisation des variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_functions import create_preprocessor\n",
    "\n",
    "preprocessor = create_preprocessor()\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eedb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "complete_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "y = [1 if x == 'Yes' else 0 for x in dataframe['Churn']]\n",
    "X = dataframe.drop(columns=['customerID','Churn'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % complete_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a98c6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Élaborer un pipeline d’entraînement sous TensorFlow Keras ou PyTorch (au choix) :\n",
    "\n",
    "#### 2.1. architecture MLP pensée pour la tabulaire : \n",
    "\n",
    "  + ≥ 2 couches cachées,\n",
    "\n",
    "  + fonction de perte adaptée à une classification binaire,\n",
    "\n",
    "  + gestion éventuelle du déséquilibre de classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_functions import build_nn_model\n",
    "import tensorflow as tf\n",
    "\n",
    "y = [1 if x == 'Yes' else 0 for x in dataframe['Churn']]\n",
    "X = dataframe.drop(columns=['customerID','Churn'])\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train_0, X_test, y_train_0, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train_0, y_train_0, test_size=0.2, random_state=42, stratify=y_train_0 )\n",
    "\n",
    "deepl_classifier = build_nn_model(X_train)\n",
    "deepl_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881d0b8",
   "metadata": {},
   "source": [
    "#### 2.2. callbacks (EarlyStopping, ModelCheckpoint, TensorBoard ou équivalent) pour suivre l’entraînement,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc988bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray() if hasattr(X_train, \"toarray\") else X_train\n",
    "X_val = X_val.toarray() if hasattr(X_val, \"toarray\") else X_val\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "history = deepl_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # surveille la perte de validation\n",
    "    patience=3,            # tolère 3 époques sans amélioration\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2217824",
   "metadata": {},
   "source": [
    "#### 2.3. suivi des métriques : ROC-AUC, F1-score, Recall sur la classe Churn = Yes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ce738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b017be6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Évaluer, comparer, justifier :\n",
    "\n",
    "\n",
    "fixer un baseline simple (régression logistique ou arbre de décision) pour mesurer le gain du réseau,\n",
    "\n",
    "\n",
    "analyser les courbes d’apprentissage, la matrice de confusion, le ROC, les distributions des scores,\n",
    "\n",
    "\n",
    "expliquer (au moins qualitativement) les variables les plus influentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b468b8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. Exporter le modèle + artefacts :\n",
    "\n",
    "\n",
    "binaire du modèle (SavedModel ↔ TensorFlow / fichier .pt ↔ PyTorch),\n",
    "\n",
    "\n",
    "scaler / encoder,\n",
    "\n",
    "\n",
    "script ou notebook d’inférence qui charge les artefacts et prédit le churn sur de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9d07c",
   "metadata": {},
   "source": [
    "## 3. Fonctionnalités obligatoires (MVP)\n",
    "\n",
    "\n",
    "<table style=\"width:75%\">\n",
    "  <tr>\n",
    "    <th>Bloc</th>\n",
    "    <th>Exigences clés</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Data Prep</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>Nettoyage & typage correct de toutes les colonnes</li>\n",
    "            <li>Encodage systématique des catégorielle</li>\n",
    "            <li>Split train / val / test (stratifié)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Modélisation</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>MLP implémenté from scratch sous TF /Keras ou PyTorch (pas d’API AutoML)</li>\n",
    "            <li>Backprop + optimiseur (Adam ou SGD)</li>\n",
    "            <li>Gestion du déséquilibre (pondération ou autre)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Suivi & répétabilité</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>TensorBoard ou PyTorch Lightning logger </li>\n",
    "        <li>Seeds fixés + README détaillant la reproduction</li>\n",
    "        <li>ModelCheckpoint pour restaurer le meilleur modèle</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Évaluation</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>ROC-AUC ≥ 0 .80 OU F1 ≥ 0 .60</li>\n",
    "        <li>Rapport comparant le réseau au baseline</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Collaboration Git</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>1 branch = 1 feature</li>\n",
    "        <li> Pull request systématique avec description</li>\n",
    "      </ul> \n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cddd8",
   "metadata": {},
   "source": [
    "## 4. Détails techniques & considérations\n",
    "Imbalance : la classe Churn = Yes ≈ 26 %.\n",
    "\n",
    "\n",
    "Pré-processing dans le même pipeline que l’inférence (pas de données “fuites” entre train et test).\n",
    "\n",
    "\n",
    "Hyperparamètres : batch_size, learning_rate, nb_neurones par couche ; explorez‐les rapidement (Random Search / KerasTuner / Ray Tune) mais documentez votre stratégie.\n",
    "\n",
    "\n",
    "Éthique & RGPD : aucune donnée personnellement identifiable ne doit sortir du cadre du projet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b378",
   "metadata": {},
   "source": [
    "## 5. Ressources utiles\n",
    "\n",
    "Docs officielles :\n",
    " \n",
    "\n",
    "TensorFlow /Keras : https://www.tensorflow.org/api_docs\n",
    "\n",
    "\n",
    "PyTorch : https://pytorch.org/docs/\n",
    "\n",
    "\n",
    "scikit-learn preprocessing : https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "\n",
    "Outils :\n",
    "\n",
    "\n",
    "KerasTuner, Optuna (hyper-tuning)\n",
    "\n",
    "\n",
    "Imbalanced-learn (rééchantillonnage)\n",
    "\n",
    "\n",
    "Cours/vidéos :\n",
    "\n",
    "\n",
    "DeepLearning.AI TensorFlow Developer (Coursera) – chapitres 2 & 3\n",
    "\n",
    "\n",
    "PyTorch Lightning Crash Course (YouTube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7399",
   "metadata": {},
   "source": [
    "## 6. Livrables\n",
    "Code source python propre et documenté\n",
    "\n",
    "\n",
    "ROC-AUC ≥ 0 .80 ou F1 ≥ 0 .60\n",
    "\n",
    "\n",
    "README clair, pas de données personnelles commitées\n",
    "\n",
    "\n",
    "Présentation prête (10 min max et tous les membres du groupes doivent parler)\n",
    "\n",
    "\n",
    "\n",
    "Groupe pour le brief\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
