{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1b5428",
   "metadata": {},
   "source": [
    "# Brief Métier : Prédiction de Churn Clients avec le Deep Learning\n",
    "\n",
    "## 1. Contexte professionnel\n",
    "Vous êtes Data Scientists dans une ESN (Entreprise de Services Numériques) qui accompagne les opérateurs télécoms dans la réduction de la perte d’abonnés.\n",
    "Votre nouveau client, TelcoNova, souhaite anticiper les départs de ses clients (churn) afin d’orienter ses campagnes de rétention.\n",
    "Il met à votre disposition un extrait anonymisé de sa base CRM (le jeu Telco Customer Churn, déjà pré-nettoyé en grande partie) et vous laisse 3 jours pour livrer un premier prototype de modèle de prédiction exploitable en production.\n",
    "TelcoNova exige un livrable reproductible et facilement intégrable par ses équipes MLOps ; vous travaillerez en binôme, en suivant les bonnes pratiques Git / GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5806396",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Votre mission\n",
    "\n",
    "### 1. Explorer & préparer les données :\n",
    "\n",
    "audit qualité, gestion des valeurs manquantes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3c5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: customerID, 7043 values.\n",
      "1: gender, 2 values: Female, Male\n",
      "2: SeniorCitizen, 2 int64 values: 0, 1\n",
      "3: Partner, 2 values: Yes, No\n",
      "4: Dependents, 2 values: No, Yes\n",
      "5: tenure, 73 int64 values.\n",
      "6: PhoneService, 2 values: No, Yes\n",
      "7: MultipleLines, 3 values: No phone service, No, Yes\n",
      "8: InternetService, 3 values: DSL, Fiber optic, No\n",
      "9: OnlineSecurity, 3 values: No, Yes, No internet service\n",
      "10: OnlineBackup, 3 values: Yes, No, No internet service\n",
      "11: DeviceProtection, 3 values: No, Yes, No internet service\n",
      "12: TechSupport, 3 values: No, Yes, No internet service\n",
      "13: StreamingTV, 3 values: No, Yes, No internet service\n",
      "14: StreamingMovies, 3 values: No, Yes, No internet service\n",
      "15: Contract, 3 values: Month-to-month, One year, Two year\n",
      "16: PaperlessBilling, 2 values: Yes, No\n",
      "17: PaymentMethod, 4 values: Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)\n",
      "18: MonthlyCharges, 1585 float64 values.\n",
      "19: TotalCharges, 6531 values.\n",
      "20: Churn, 2 values: No, Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataframe = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "for index, column in enumerate ( dataframe.columns) :\n",
    "    print(f\"{index}: {column}, \", end='')\n",
    "    num_values = dataframe[column].nunique()\n",
    "    is_numeric = pd.api.types.is_numeric_dtype(dataframe[column])\n",
    "    numeric_type = str(dataframe[column].dtype)\n",
    "    print(f\"{num_values}{(' '+numeric_type) if is_numeric else ''} values\", end='')\n",
    "    if num_values < 10 :\n",
    "        print(f\": \" + ', '.join(str(x) for x in dataframe[column].unique())) \n",
    "    else :\n",
    "        print(f\".\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28543bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonthlyCharges:\n",
      "1585 values\n",
      "\n",
      "TotalCharges:\n",
      "  [ ]\n",
      "6530 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exploration des colonnes à plus de 10 valeurs\n",
    "\n",
    "def check_float(dataframe : pd.DataFrame, columnname : str) :\n",
    "    print(f\"{columnname}:\")\n",
    "    numericount =0\n",
    "    for value in dataframe[columnname].unique() :\n",
    "        try :\n",
    "            numeric_value = float(value)\n",
    "            numericount+=1\n",
    "        except :\n",
    "            print(f\"  [{value}]\")\n",
    "\n",
    "    print(f\"{numericount} values\")\n",
    "    print()\n",
    "\n",
    "# 0: customerID, 7043 values => drop column\n",
    "# 5: tenure, 73 int64 values => int64\n",
    "# 18: MonthlyCharges, 1585 float64 values => float64\n",
    "check_float(dataframe, 'MonthlyCharges')\n",
    "\n",
    "# 19: TotalCharges, 6531 values : Exploration\n",
    "check_float(dataframe, 'TotalCharges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..app.pipeline_functions import exclude_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892c9ee",
   "metadata": {},
   "source": [
    "encodage des variables / normalisation / standardisation des variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "preprocessor = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (make_pipeline(\n",
    "                FunctionTransformer(convert_age_to_study_years, validate=False),\n",
    "                StandardScaler()\n",
    "            ), ['age']\n",
    "        ),\n",
    "        (StandardScaler(), ['income']\n",
    "        ),\n",
    "        (make_pipeline(\n",
    "                FunctionTransformer(lambda x: x.squeeze(), validate=False),\n",
    "                TfidfVectorizer()\n",
    "            ), ['description']\n",
    "        ),\n",
    "\n",
    "        (OneHotEncoder(), [\"gender\"]), # 2 values: Female, Male\n",
    "        (OneHotEncoder(), [\"SeniorCitizen\"]), #, 2 int64 values: 0, 1\n",
    "        (OneHotEncoder(), [\"Partner\"]), #2 values: Yes, No\n",
    "        (OneHotEncoder(),[\"Dependents\"]), # 22 values: No, Yes\n",
    "        (OneHotEncoder(),[\"tenure\"]), # 73 int64 values.\n",
    "        (OneHotEncoder(),[\"PhoneService\"]), # 2 values: No, Yes\n",
    "        (OneHotEncoder(),[\"MultipleLines\"]), # 3 values: No phone service, No, Yes\n",
    "        (OneHotEncoder(),[\"InternetService\"]), # 3 values: DSL, Fiber optic, No\n",
    "        (OneHotEncoder(),[\"OnlineSecurity\"]), #  3 values: No, Yes, No internet service\n",
    "        (OneHotEncoder(),[\"OnlineBackup\"]), # 3 values: Yes, No, No internet service\n",
    "        (OneHotEncoder(),[\"DeviceProtection\"]), # 3 values: No, Yes, No internet service        \n",
    "        (OneHotEncoder(),[\"TechSupport\"]), # 3 values: No, Yes, No internet service\n",
    "        (OneHotEncoder(),[\"StreamingTV\"]), # 3 values: No, Yes, No internet service\n",
    "        (OneHotEncoder(),[\"StreamingMovies\"]), # 3 values: No, Yes, No internet service\n",
    "        (OneHotEncoder(),[\"Contract\"]), # 3 values: Month-to-month, One year, Two year\n",
    "        (OneHotEncoder(),[\"PaperlessBilling\"]), # 2 values: Yes, No\n",
    "        (OneHotEncoder(),[\"PaymentMethod\"]), # 4 values: Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)\n",
    "        (OneHotEncoder(),[\"MonthlyCharges\"]), # 1585 float64 values.\n",
    "        (OneHotEncoder(),[\"TotalCharges\"]), # 6531 values.\n",
    "        (OneHotEncoder(),[\"Churn\"]), # 2 values: No, Yes)\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a98c6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Élaborer un pipeline d’entraînement sous TensorFlow Keras ou PyTorch (au choix) :\n",
    "\n",
    "\n",
    "architecture MLP pensée pour la tabulaire : ≥ 2 couches cachées,\n",
    "\n",
    "\n",
    "fonction de perte adaptée à une classification binaire + gestion éventuelle du déséquilibre de classes.\n",
    "\n",
    "\n",
    "callbacks (EarlyStopping, ModelCheckpoint, TensorBoard ou équivalent) pour suivre l’entraînement,\n",
    "\n",
    "\n",
    "suivi des métriques : ROC-AUC, F1-score, Recall sur la classe Churn = Yes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b017be6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Évaluer, comparer, justifier :\n",
    "\n",
    "\n",
    "fixer un baseline simple (régression logistique ou arbre de décision) pour mesurer le gain du réseau,\n",
    "\n",
    "\n",
    "analyser les courbes d’apprentissage, la matrice de confusion, le ROC, les distributions des scores,\n",
    "\n",
    "\n",
    "expliquer (au moins qualitativement) les variables les plus influentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b468b8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. Exporter le modèle + artefacts :\n",
    "\n",
    "\n",
    "binaire du modèle (SavedModel ↔ TensorFlow / fichier .pt ↔ PyTorch),\n",
    "\n",
    "\n",
    "scaler / encoder,\n",
    "\n",
    "\n",
    "script ou notebook d’inférence qui charge les artefacts et prédit le churn sur de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9d07c",
   "metadata": {},
   "source": [
    "## 3. Fonctionnalités obligatoires (MVP)\n",
    "\n",
    "\n",
    "<table style=\"width:75%\">\n",
    "  <tr>\n",
    "    <th>Bloc</th>\n",
    "    <th>Exigences clés</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Data Prep</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>Nettoyage & typage correct de toutes les colonnes</li>\n",
    "            <li>Encodage systématique des catégorielle</li>\n",
    "            <li>Split train / val / test (stratifié)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Modélisation</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>MLP implémenté from scratch sous TF /Keras ou PyTorch (pas d’API AutoML)</li>\n",
    "            <li>Backprop + optimiseur (Adam ou SGD)</li>\n",
    "            <li>Gestion du déséquilibre (pondération ou autre)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Suivi & répétabilité</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>TensorBoard ou PyTorch Lightning logger </li>\n",
    "        <li>Seeds fixés + README détaillant la reproduction</li>\n",
    "        <li>ModelCheckpoint pour restaurer le meilleur modèle</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Évaluation</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>ROC-AUC ≥ 0 .80 OU F1 ≥ 0 .60</li>\n",
    "        <li>Rapport comparant le réseau au baseline</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Collaboration Git</td>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>1 branch = 1 feature</li>\n",
    "        <li> Pull request systématique avec description</li>\n",
    "      </ul> \n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cddd8",
   "metadata": {},
   "source": [
    "## 4. Détails techniques & considérations\n",
    "Imbalance : la classe Churn = Yes ≈ 26 %.\n",
    "\n",
    "\n",
    "Pré-processing dans le même pipeline que l’inférence (pas de données “fuites” entre train et test).\n",
    "\n",
    "\n",
    "Hyperparamètres : batch_size, learning_rate, nb_neurones par couche ; explorez‐les rapidement (Random Search / KerasTuner / Ray Tune) mais documentez votre stratégie.\n",
    "\n",
    "\n",
    "Éthique & RGPD : aucune donnée personnellement identifiable ne doit sortir du cadre du projet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b378",
   "metadata": {},
   "source": [
    "## 5. Ressources utiles\n",
    "\n",
    "Docs officielles :\n",
    " \n",
    "\n",
    "TensorFlow /Keras : https://www.tensorflow.org/api_docs\n",
    "\n",
    "\n",
    "PyTorch : https://pytorch.org/docs/\n",
    "\n",
    "\n",
    "scikit-learn preprocessing : https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "\n",
    "Outils :\n",
    "\n",
    "\n",
    "KerasTuner, Optuna (hyper-tuning)\n",
    "\n",
    "\n",
    "Imbalanced-learn (rééchantillonnage)\n",
    "\n",
    "\n",
    "Cours/vidéos :\n",
    "\n",
    "\n",
    "DeepLearning.AI TensorFlow Developer (Coursera) – chapitres 2 & 3\n",
    "\n",
    "\n",
    "PyTorch Lightning Crash Course (YouTube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7399",
   "metadata": {},
   "source": [
    "## 6. Livrables\n",
    "Code source python propre et documenté\n",
    "\n",
    "\n",
    "ROC-AUC ≥ 0 .80 ou F1 ≥ 0 .60\n",
    "\n",
    "\n",
    "README clair, pas de données personnelles commitées\n",
    "\n",
    "\n",
    "Présentation prête (10 min max et tous les membres du groupes doivent parler)\n",
    "\n",
    "\n",
    "\n",
    "Groupe pour le brief\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
