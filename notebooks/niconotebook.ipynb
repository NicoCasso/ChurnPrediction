{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1b5428",
   "metadata": {},
   "source": [
    "# Brief Métier : Prédiction de Churn Clients avec le Deep Learning\n",
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 1. Contexte professionnel\n",
    "Vous êtes **Data Scientists** dans une ESN (Entreprise de Services Numériques) qui accompagne les opérateurs télécoms dans la réduction de la perte d’abonnés.\n",
    "Votre nouveau client, **TelcoNova**, souhaite anticiper les départs de ses clients (churn) afin d’orienter ses campagnes de rétention.\n",
    "\n",
    "Il met à votre disposition un extrait anonymisé de sa base CRM (le jeu Telco Customer Churn, déjà pré-nettoyé en grande partie) et vous laisse **3 jours** pour livrer un premier prototype de modèle de prédiction exploitable en production.\n",
    "\n",
    "TelcoNova exige un livrable reproductible et facilement intégrable par ses équipes MLOps ; vous travaillerez **en binôme**, en suivant les bonnes pratiques Git / GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5806396",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 2. Votre mission\n",
    "\n",
    "1. **Explorer & préparer les données** :\n",
    "\n",
    "    + audit qualité, gestion des valeurs manquantes, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataframe = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "for index, column in enumerate ( dataframe.columns) :\n",
    "    print(f\"{index}: {column}, \", end='')\n",
    "    num_values = dataframe[column].nunique()\n",
    "    is_numeric = pd.api.types.is_numeric_dtype(dataframe[column])\n",
    "    numeric_type = str(dataframe[column].dtype)\n",
    "    print(f\"{num_values}{(' '+numeric_type) if is_numeric else ''} values\", end='')\n",
    "    if num_values < 10 :\n",
    "        print(f\": \" + ', '.join(str(x) for x in dataframe[column].unique())) \n",
    "    else :\n",
    "        print(f\".\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28543bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration des colonnes à plus de 10 valeurs\n",
    "\n",
    "def check_float(dataframe : pd.DataFrame, columnname : str) :\n",
    "    print(f\"{columnname}:\")\n",
    "    numericount =0\n",
    "    for value in dataframe[columnname].unique() :\n",
    "        try :\n",
    "            numeric_value = float(value)\n",
    "            numericount+=1\n",
    "        except :\n",
    "            print(f\"  [{value}]\")\n",
    "\n",
    "    print(f\"{numericount} values\")\n",
    "    print()\n",
    "\n",
    "# 0: customerID, 7043 values => drop column\n",
    "# 5: tenure, 73 int64 values => int64\n",
    "# 18: MonthlyCharges, 1585 float64 values => float64\n",
    "check_float(dataframe, 'MonthlyCharges')\n",
    "\n",
    "# 19: TotalCharges, 6531 values : Exploration\n",
    "check_float(dataframe, 'TotalCharges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le chemin absolu du dossier src au sys.path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from pipeline_functions import exclude_spaces\n",
    "\n",
    "print(f\"before : {dataframe['TotalCharges'].dtype}\")\n",
    "\n",
    "dataframe2 = exclude_spaces('TotalCharges')(dataframe)\n",
    "\n",
    "print(f\"after : {dataframe2['TotalCharges'].dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892c9ee",
   "metadata": {},
   "source": [
    "  + encodage des variables / normalisation / standardisation des variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_functions import create_preprocessor\n",
    "\n",
    "preprocessor = create_preprocessor()\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eedb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.set_params()\n",
    "\n",
    "\n",
    "complete_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", sklearn_model)]\n",
    ")\n",
    "\n",
    "y = [1 if x == 'Yes' else 0 for x in dataframe['Churn']]\n",
    "X = dataframe.drop(columns=['customerID','Churn'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = complete_pipeline.predict(X_test)\n",
    "y_proba = complete_pipeline.predict_proba(X_test)[:, 1]  # pour le ROC AUC\n",
    "\n",
    "# Évaluation\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"model score: %.3f\" % complete_pipeline.score(X_test, y_test))\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"ROC AUC  : {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a98c6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. **Élaborer un pipeline d’entraînement** sous **TensorFlow Keras ou PyTorch** (au choix) :\n",
    "\n",
    "  + architecture MLP pensée pour la tabulaire : ≥ 2 couches cachées,\n",
    "\n",
    "  + fonction de perte adaptée à une classification binaire,\n",
    "\n",
    "  + gestion éventuelle du déséquilibre de classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add comment\n",
    "\n",
    "from pipeline_functions import build_nn_model\n",
    "import tensorflow as tf\n",
    "\n",
    "y = [1 if x == 'Yes' else 0 for x in dataframe['Churn']]\n",
    "X = dataframe.drop(columns=['customerID','Churn'])\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train_0, X_test, y_train_0, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train_0, y_train_0, test_size=0.2, random_state=42, stratify=y_train_0 )\n",
    "\n",
    "deepl_classifier = build_nn_model(X_train)\n",
    "deepl_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881d0b8",
   "metadata": {},
   "source": [
    "  + callbacks (EarlyStopping, ModelCheckpoint, TensorBoard ou équivalent) pour suivre l’entraînement,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc988bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray() if hasattr(X_train, \"toarray\") else X_train\n",
    "X_val = X_val.toarray() if hasattr(X_val, \"toarray\") else X_val\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "history = deepl_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # surveille la perte de validation\n",
    "    patience=3,            # tolère 3 époques sans amélioration\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2217824",
   "metadata": {},
   "source": [
    "  + suivi des métriques : ROC-AUC, F1-score, Recall sur la classe Churn = Yes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ce738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc, test_pre, test_rec, test_auc, test_f1s = deepl_classifier.evaluate(X_val, y_val)\n",
    "metrics = deepl_classifier.evaluate(X_val,y_val)\n",
    "test_loss, test_acc, test_pre, test_auc = metrics\n",
    "print(f\"Loss      : {test_loss:.4f}\")\n",
    "print(f\"Accuracy  : {test_acc:.4f}\")\n",
    "print(f\"Precision : {test_pre:.4f}\")\n",
    "# print(f\"Recall    : {test_rec:.4f}\")\n",
    "print(f\"ROC-AUC   : {test_auc:.4f}\")\n",
    "#print(f\"F1-score  : {test_f1s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(ax, title:str, history, validation=True):\n",
    "    ax.plot(history.history[title], label=f\"Train {title}\")\n",
    "\n",
    "    val_title = \"val_\"+title\n",
    "    if validation and val_title in history.history:\n",
    "        ax.plot(history.history[val_title], label=f\"Val {title}\")\n",
    "        \n",
    "    ax.set_title(f\"Évolution de la {title}\")\n",
    "    ax.set_xlabel('Époque')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "# Créer la figure et les axes (4 plots côte à côte)\n",
    "fig1, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "plot_history(axs[0], \"loss\", history)\n",
    "plot_history(axs[1], \"accuracy\", history)\n",
    "plot_history(axs[2], \"precision\",history)\n",
    "plot_history(axs[3], \"roc_auc\", history)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b017be6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. Évaluer, comparer, justifier :\n",
    "\n",
    "  + fixer un **baseline** simple (régression logistique ou arbre de décision) pour mesurer le gain du réseau,\n",
    "\n",
    "  + analyser les courbes d’apprentissage, la matrice de confusion, le ROC, les distributions des scores,\n",
    "\n",
    "  + expliquer (au moins qualitativement) les variables les plus influentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b468b8",
   "metadata": {},
   "source": [
    "4. Exporter le modèle + artefacts :\n",
    "\n",
    "  + binaire du modèle (<span style=\"color: lightgreen;\"><b>SavedModel</b></span> ↔ TensorFlow / fichier <span style=\"color: lightgreen;\"><b>.pt</b></span> ↔ PyTorch),\n",
    "\n",
    "  + scaler / encoder,\n",
    "\n",
    "  + script ou notebook d’inférence qui charge les artefacts et prédit le churn sur de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9d07c",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 3. Fonctionnalités obligatoires (MVP)\n",
    "\n",
    "\n",
    "<table style=\"width:75%\">\n",
    "  <tr>\n",
    "    <th>Bloc</th>\n",
    "    <th>Exigences clés</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Data Prep</th>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>Nettoyage & typage correct de <b>toutes</b> les colonnes</li>\n",
    "            <li>Encodage systématique des catégorielle</li>\n",
    "            <li>Split train / val / test (stratifié)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Modélisation</th>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>MLP implémenté <b>from scratch</b> sous TF /Keras <b>ou</b> PyTorch (pas d’API AutoML)</li>\n",
    "            <li>Backprop + optimiseur (Adam ou SGD)</li>\n",
    "            <li>Gestion du déséquilibre (pondération ou autre)</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Suivi & répétabilité</th>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>TensorBoard ou PyTorch Lightning logger </li>\n",
    "        <li>Seeds fixés + README détaillant la reproduction</li>\n",
    "        <li>ModelCheckpoint pour restaurer le meilleur modèle</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Évaluation</th>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>ROC-AUC ≥ 0 .80 <b>OU</b> F1 ≥ 0 .60</li>\n",
    "        <li>Rapport comparant le réseau au baseline</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Collaboration Git</th>\n",
    "    <td>\n",
    "      <ul>\n",
    "        <li>1 branch = 1 feature</li>\n",
    "        <li> Pull request systématique avec description</li>\n",
    "      </ul> \n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cddd8",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 4. Détails techniques & considérations\n",
    "  + **Imbalance** : la classe Churn = Yes ≈ 26 %.\n",
    "\n",
    "  + **Pré-processing dans le même pipeline** que l’inférence (pas de données “fuites” entre train et test).\n",
    "\n",
    "  + **Hyperparamètres** : batch_size, learning_rate, nb_neurones par couche ; explorez‐les rapidement (Random Search / KerasTuner / Ray Tune) mais documentez votre stratégie.\n",
    "\n",
    "  + **Éthique & RGPD** : aucune donnée personnellement identifiable ne doit sortir du cadre du projet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b378",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 5. Ressources utiles\n",
    "\n",
    "  + **Docs officielles** :\n",
    " \n",
    "    + TensorFlow /Keras : https://www.tensorflow.org/api_docs\n",
    "    + PyTorch : https://pytorch.org/docs/\n",
    "    + scikit-learn preprocessing : https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    " + **Outils** :\n",
    "\n",
    "    + KerasTuner, Optuna (hyper-tuning)\n",
    "    + Imbalanced-learn (rééchantillonnage)\n",
    "\n",
    "  + **Cours/vidéos** :\n",
    "\n",
    "    + [DeepLearning.AI TensorFlow Developer (Coursera) – chapitres 2 & 3](http://DeepLearning.AI)\n",
    "    + [PyTorch Lightning Crash Course (YouTube)](https://www.youtube.com/watch?v=OIenNRt2bjg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7399",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## 6. Livrables\n",
    "  + Code source python propre et documenté\n",
    "\n",
    "  + ROC-AUC ≥ 0 .80 ou F1 ≥ 0 .60\n",
    "\n",
    "  + README clair, pas de données personnelles commitées\n",
    "\n",
    "  + Présentation prête (10 min max et tous les membres du groupes doivent parler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf821676",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________________\n",
    "\n",
    "  + Groupe pour le brief :\n",
    "    \n",
    "    G1 = Khadija A.\t+ Wael\t\n",
    "\n",
    "    G2 = Victor\t+ Maxime + Antoine\n",
    "\n",
    "    G3 = Ludivine + Dorothée\t\n",
    "\n",
    "    G4 = Malek + Nicolas G\t\n",
    "\n",
    "    G6 = Hacène + Elliandy\t\n",
    "\n",
    "    G7 = Raouf + Léo\t\n",
    "\n",
    "    G8 = Samuel\t+ Michael\t\n",
    "\n",
    "    G9 = Sami +\tGauthier\t\n",
    "\n",
    "    G10 = Nicolas C + David\t\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
