# ğŸ§  TelcoNova - PrÃ©diction de Churn Clients avec le Deep Learning

## ğŸ“Œ Contexte

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre d'une mission pour **TelcoNova**, opÃ©rateur tÃ©lÃ©com souhaitant **anticiper les dÃ©parts de ses clients** (churn). En tant que Data Scientists au sein dâ€™une ESN, notre objectif est de livrer un **prototype de modÃ¨le de prÃ©diction** du churn, performant, reproductible et prÃªt pour lâ€™intÃ©gration en production.

## ğŸ¯ Objectifs

- Explorer, nettoyer et prÃ©parer les donnÃ©es CRM.
- Concevoir un pipeline de modÃ©lisation **Deep Learning** (MLP) sous **TensorFlow/Keras** ou **PyTorch**.
- Comparer les performances du modÃ¨le Ã  une baseline simple.
- Fournir un modÃ¨le exportable avec ses artefacts pour une utilisation en production.
- Respecter les bonnes pratiques Git et assurer la reproductibilitÃ©.

## ğŸ”§ Stack technique

- Python â‰¥ 3.9
- TensorFlow / Keras ou PyTorch
- scikit-learn, pandas, matplotlib, seaborn
- TensorBoard ou PyTorch Lightning pour le logging
- Imbalanced-learn (gestion du dÃ©sÃ©quilibre)
- KerasTuner / Optuna pour le tuning
- Git & GitHub

## ğŸ“‚ Structure du projet

.
â”œâ”€â”€ data
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ img
â”‚   â”œâ”€â”€ Evolution_of_training.png
â”‚   â”œâ”€â”€ Matrice_de_Confusion.png
â”‚   â””â”€â”€ shap_summary_plot.png
â”œâ”€â”€ model
â”‚   â””â”€â”€ model.pkl
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ CHURNPREDICTION
â”‚   â”‚   â””â”€â”€ grid_search
â”‚   â”‚       â”œâ”€â”€ oracle.json
â”‚   â”‚       â”œâ”€â”€ trial_00
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_01
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_02
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_03
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_04
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_05
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_06
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_07
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_08
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â”œâ”€â”€ trial_09
â”‚   â”‚       â”‚   â”œâ”€â”€ build_config.json
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint.weights.h5
â”‚   â”‚       â”‚   â””â”€â”€ trial.json
â”‚   â”‚       â””â”€â”€ tuner0.json
â”‚   â””â”€â”€ davidnotebook.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ src
    â”œâ”€â”€ deeplmodel.py
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ pipeline_functions.py
    â””â”€â”€ regression_logistic.py

## âœ… FonctionnalitÃ©s livrÃ©es

### ğŸ§¼ PrÃ©paration des donnÃ©es

- Nettoyage et typage cohÃ©rents de toutes les colonnes
- Encodage des variables catÃ©gorielles (One-Hot ou Ordinal)
- Normalisation / standardisation des variables numÃ©riques
- Split stratifiÃ© : train / validation / test

### ğŸ§  ModÃ©lisation

- MLP (â‰¥ 2 couches cachÃ©es) implÃ©mentÃ© **from scratch**
- Fonction de perte : `BinaryCrossentropy`, avec pondÃ©ration
- Optimiseur : `Adam`
- **Gestion du dÃ©sÃ©quilibre** : pondÃ©ration ou sur-Ã©chantillonnage
- EarlyStopping + ModelCheckpoint
- Suivi via TensorBoard / LightningLogger

### ğŸ“Š Ã‰valuation

- **Baseline** : rÃ©gression logistique
- MÃ©triques : **ROC-AUC**, **F1-score**, **Recall** (focus sur `Churn = Yes`)
- Visualisations : courbe ROC, matrice de confusion, courbes dâ€™apprentissage
- Explication des variables influentes (feature importance + SHAP ou approches simples)

### ğŸ“¦ Export / InfÃ©rence

- ModÃ¨le enregistrÃ© : `SavedModel` (TF) ou `.pt` (PyTorch)
- Encoders + scalers sauvegardÃ©s
- Script dâ€™infÃ©rence prÃªt Ã  lâ€™emploi sur nouveaux clients

## ğŸ“Œ ReproductibilitÃ©

- **Seed fixÃ©e** pour tous les composants pseudo-alÃ©atoires
- ModÃ¨le sauvegardÃ© et restaurable
- Instructions de rÃ©exÃ©cution documentÃ©es
- Suivi de toutes les fonctionnalitÃ©s via branches Git + pull requests

## ğŸ” Lancer le projet

### Installation

```bash
git clone https://github.com/<votre-org>/telco-churn-prediction.git
cd telco-churn-prediction
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

| ModÃ¨le            | ROC-AUC  | F1-Score | Recall (Churn) |
| ----------------- | -------- | -------- | -------------- |
| Baseline (LogReg) | 0.76     | 0.58     | 0.61           |
| MLP Final         | **0.83** | **0.63** | **0.68**       |

## ğŸ“š Ressources

- [TensorFlow API Docs](https://www.tensorflow.org/api_docs)
- [PyTorch Docs](https://pytorch.org/docs/)
- [KerasTuner](https://keras.io/keras_tuner/)
- [Imbalanced-learn](https://imbalanced-learn.org/stable/)
- *DeepLearning.AI TensorFlow Developer* (Coursera)
- *PyTorch Lightning Crash Course* (YouTube)

## ğŸ‘¥ Auteurs

- **David** (Data Scientist)
- **Nicolas** (Data Scientist)
